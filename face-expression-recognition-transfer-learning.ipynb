{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":29907,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os \nimport tensorflow as tf \nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import RMSprop\nfrom keras.applications import MobileNet\nfrom keras.callbacks import ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T05:38:28.378560Z","iopub.execute_input":"2023-12-10T05:38:28.378914Z","iopub.status.idle":"2023-12-10T05:38:37.189707Z","shell.execute_reply.started":"2023-12-10T05:38:28.378859Z","shell.execute_reply":"2023-12-10T05:38:37.188717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('../input/face-expression-recognition-dataset/images/')\ntrain_path = './train/'\nvalidation_path = './validation/'\nos.listdir()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-12-10T05:38:37.191737Z","iopub.execute_input":"2023-12-10T05:38:37.192066Z","iopub.status.idle":"2023-12-10T05:38:37.245625Z","shell.execute_reply.started":"2023-12-10T05:38:37.192012Z","shell.execute_reply":"2023-12-10T05:38:37.244782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying images from the training directory","metadata":{}},{"cell_type":"code","source":"plt.figure(0, figsize=(48,48))\ncpt = 0\n\nfor expression in os.listdir(train_path):\n    for i in range(1,6):\n        cpt = cpt + 1\n        sp=plt.subplot(7,5,cpt)\n        sp.axis('Off')\n        img_path = train_path + expression + \"/\" +os.listdir(train_path + expression)[i]\n        img = load_img( img_path, target_size=(48,48))\n        plt.imshow(img, cmap=\"gray\")\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T05:38:37.246745Z","iopub.execute_input":"2023-12-10T05:38:37.247005Z","iopub.status.idle":"2023-12-10T05:38:44.234676Z","shell.execute_reply.started":"2023-12-10T05:38:37.246968Z","shell.execute_reply":"2023-12-10T05:38:44.233156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generators","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255,\n                                   rotation_range=30,\n                                   zoom_range=0.2)\n\nvalidation_datagen = ImageDataGenerator(rescale=1/255)\n\nbatch_size = 128\n\n\ntrain_generator = train_datagen.flow_from_directory (train_path,   \n                                                     target_size=(48, 48),  \n                                                     batch_size=batch_size,\n                                                     shuffle=True,\n                                                     class_mode='categorical',\n                                                     color_mode=\"rgb\")\n\n\nvalidation_generator = validation_datagen.flow_from_directory(validation_path,  \n                                                              target_size=(48,48), \n                                                              batch_size=batch_size,\n                                                              class_mode='categorical',\n                                                              color_mode=\"rgb\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T05:38:44.236093Z","iopub.execute_input":"2023-12-10T05:38:44.236472Z","iopub.status.idle":"2023-12-10T05:39:22.615788Z","shell.execute_reply.started":"2023-12-10T05:38:44.236416Z","shell.execute_reply":"2023-12-10T05:39:22.614799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Our Model","metadata":{}},{"cell_type":"code","source":"#Loading the Mobilenet model \nfeaturizer = MobileNet(include_top=False, weights='imagenet', input_shape=(48,48,3))\n\n#Since we have 7 types of expressions, we'll set the nulber of classes to 7\nnum_classes = 7\n\n#Adding some layers to the feturizer\nx = Flatten()(featurizer.output)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = BatchNormalization()(x)\npredictions = Dense(num_classes, activation = 'softmax')(x)\n\n\n\nmodel = Model(input = featurizer.input, output = predictions)\n\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T05:39:22.617616Z","iopub.execute_input":"2023-12-10T05:39:22.617911Z","iopub.status.idle":"2023-12-10T05:39:29.378231Z","shell.execute_reply.started":"2023-12-10T05:39:22.617868Z","shell.execute_reply":"2023-12-10T05:39:29.377347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training \nCallbacks : we'll use **ModelCheckpoint**, which allows us to save our model's weights, and by setting **save_best_only** parameter to true, the latest best model according to the quantity monitored (which is val_accuracy here) won't be overwritten. Our **mode** parameter is set to max because we want the val_accuracy to be the highest. ","metadata":{}},{"cell_type":"code","source":"model_weights_path = r'/kaggle/working/model_weights.h5'\n\ncheckpoint = ModelCheckpoint(model_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n\nhistory = model.fit(train_generator,\n                        steps_per_epoch=train_generator.n//train_generator.batch_size,\n                        validation_steps=validation_generator.n//validation_generator.batch_size,\n                        epochs=100,\n                        verbose=1,\n                        validation_data = validation_generator,\n                        callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T05:39:56.185477Z","iopub.execute_input":"2023-12-10T05:39:56.185842Z","iopub.status.idle":"2023-12-10T07:49:05.618497Z","shell.execute_reply.started":"2023-12-10T05:39:56.185795Z","shell.execute_reply":"2023-12-10T07:49:05.617411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Our Model","metadata":{}},{"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(r'/kaggle/working/model.json', \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:49:12.273122Z","iopub.execute_input":"2023-12-10T07:49:12.273528Z","iopub.status.idle":"2023-12-10T07:49:12.291527Z","shell.execute_reply.started":"2023-12-10T07:49:12.273465Z","shell.execute_reply":"2023-12-10T07:49:12.290641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:50:04.363035Z","iopub.execute_input":"2023-12-10T07:50:04.363455Z","iopub.status.idle":"2023-12-10T07:50:04.611216Z","shell.execute_reply.started":"2023-12-10T07:50:04.363394Z","shell.execute_reply":"2023-12-10T07:50:04.610467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy & Loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nplt.subplot(1, 2, 1)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='upper right')\n\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='lower right')\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}